# NLP Mini Projects

This repository is a collection of small NLP experiments created for learning and practice. Each experiment focuses on understanding a specific concept such as data loading, model training, evaluation, and experimentation with sequential neural networks using simple datasets.

1. [Sine Wave Prediction](sine_wave_prediction.ipynb): This mini-project demonstrates a complete time-series prediction pipeline using PyTorch, where an LSTM learns to forecast the next value of a sine signal from a fixed-length history window. It covers synthetic signal generation (sin over a continuous range), sliding-window dataset creation (turning a 1D sequence into supervised samples), and efficient batching via TensorDataset and DataLoader. The model is a compact LSTM-based regressor (sequence encoder + linear head) trained on GPU/CPU using MSELoss and Adam, illustrating how recurrent networks capture temporal dependencies for regression tasks. Training dynamics are tracked using a loss curve, and final performance is visualized by plotting ground-truth vs predicted sine values, making it an intuitive experiment for understanding sequence modeling and next-step forecasting.

2. [Climate Sequence](climate_sequence.ipynb): This mini-project demonstrates an end-to-end time-series forecasting pipeline in PyTorch using the Kaggle Daily Delhi Climate dataset, where an LSTM learns to predict the next day’s mean temperature from a fixed-length history window. It covers loading train/test CSVs, selecting a single target series (meantemp), applying min–max normalization using training statistics, and constructing a custom Dataset that converts a continuous sequence into supervised samples via a rolling window. A compact LSTM regressor (sequence encoder + linear head) is trained on GPU/CPU using MSELoss and Adam, with torchinfo.summary used to verify model shapes and parameter counts. Training and testing losses are tracked across epochs and visualized with a clean loss curve, making it an intuitive experiment for understanding sequence modeling, window-based dataset creation, and generalization behavior on real-world temporal data.
